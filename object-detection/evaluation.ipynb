{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activitynet-100', 'activitynet-200', 'bdd100k', 'caltech101', 'caltech256', 'cifar10', 'cifar100', 'cityscapes', 'coco-2014', 'coco-2017', 'fashion-mnist', 'fiw', 'hmdb51', 'imagenet-2012', 'imagenet-sample', 'kinetics-400', 'kinetics-600', 'kinetics-700', 'kinetics-700-2020', 'kitti', 'kitti-multiview', 'lfw', 'mnist', 'open-images-v6', 'open-images-v7', 'quickstart', 'quickstart-geo', 'quickstart-groups', 'quickstart-video', 'sama-coco', 'ucf101', 'voc-2007', 'voc-2012']\n",
      "Downloading split 'validation' to '/Users/kristian/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/Users/kristian/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [9.8s elapsed, 0s remaining, 537.9 samples/s]       \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone.utils.eval.detection import evaluate_detections, DetectionResults\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from numpyencoder import NumpyEncoder\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import time\n",
    "from codecarbon import track_emissions\n",
    "\n",
    "\n",
    "\n",
    "# List available zoo datasets\n",
    "print(foz.list_zoo_datasets())\n",
    "\n",
    "#\n",
    "# Load the COCO-2017 validation split into a FiftyOne dataset\n",
    "#\n",
    "# This will download the dataset from the web, if necessary\n",
    "#\n",
    "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n",
    "#test17 = foz.load_zoo_dataset(\"coco-2017\", split=\"test\")\n",
    "\n",
    "# Give the dataset a new name, and make it persistent so that you can\n",
    "# work with it in future sessions\n",
    "dataset.name = \"coco-2017-validatio\"\n",
    "dataset.persistent = True\n",
    "#test17.name = \"coco-2017-test-example\"\n",
    "#test17.persistent = True\n",
    "# Visualize the in the App\n",
    "#session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://www.kaggle.com/models/tensorflow/ssd-mobilenet-v2/frameworks/TensorFlow2/variations/ssd-mobilenet-v2/versions/1\"\n",
    "model = hub.load(model_url)\n",
    "\n",
    "num_images_to_infer = 3000\n",
    "sampled_dataset = dataset.take(num_images_to_infer)\n",
    "coco_results = []\n",
    "\n",
    "# Iterate through each sample in the dataset\n",
    "for sample in sampled_dataset:\n",
    "    coco_sample_results = []\n",
    "\n",
    "    # Load the image\n",
    "    image_path = sample.filepath\n",
    "    image = tf.image.decode_image(tf.io.read_file(image_path), channels=3).numpy()\n",
    "    image_height, image_width, _ = image.shape\n",
    "    image_id = int(image_path[-16:-4])\n",
    "\n",
    "    # Perform inference\n",
    "    input_image = tf.convert_to_tensor(image)\n",
    "    input_image = tf.expand_dims(input_image, axis=0)\n",
    "    input_image = tf.cast(input_image, tf.uint8) \n",
    "    detections = model(input_image)\n",
    "\n",
    "    # Extract relevant information from the detections\n",
    "    boxes = detections[\"detection_boxes\"][0].numpy()\n",
    "    scores = detections[\"detection_scores\"][0].numpy()\n",
    "    labels = detections[\"detection_classes\"][0].numpy().astype(int)\n",
    "\n",
    "    # Append image id to results\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        # Convert to COCO format\n",
    "        coco_sample_results.append(\n",
    "            {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": label,\n",
    "                # Scale box to image size\n",
    "                \"bbox\":  [\n",
    "                    box[1] * image_width,\n",
    "                    box[0] * image_height,\n",
    "                    (box[3] - box[1]) * image_width,\n",
    "                    (box[2] - box[0]) * image_height,\n",
    "                ],\n",
    "                \"score\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    coco_results.extend(coco_sample_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=11.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.64s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n"
     ]
    }
   ],
   "source": [
    "# Save the results to disk\n",
    "coco_results_path = \"coco_results.json\"\n",
    "with open(coco_results_path, \"w\") as f:\n",
    "    json.dump(coco_results, f, cls=NumpyEncoder)\n",
    "\n",
    "# Load the COCO annotations for the validation split\n",
    "gt_path = 'data/coco/annotations/instances_val2017.json'\n",
    "coco_gt = COCO(gt_path)\n",
    "\n",
    "# Load the COCO results\n",
    "coco_dt = coco_gt.loadRes(coco_results_path)\n",
    "\n",
    "# Evaluate the results\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "#coco_eval.params.imgIds  = imgIds\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=365d3c62-7ad2-4a4f-8134-46e57dc13381\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2dd4b8a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(sampled_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
